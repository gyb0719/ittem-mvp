import 'dart:async';\nimport 'dart:convert';\nimport 'dart:io';\nimport 'package:flutter/foundation.dart';\nimport 'package:flutter/services.dart';\nimport 'package:shared_preferences/shared_preferences.dart';\nimport 'performance_service.dart';\n\n// ë„¤íŠ¸ì›Œí¬ ìµœì í™” ì„œë¹„ìŠ¤ - í•œêµ­ ëª¨ë°”ì¼ í™˜ê²½ íŠ¹í™”\nclass NetworkOptimizationService {\n  static final NetworkOptimizationService _instance = NetworkOptimizationService._internal();\n  factory NetworkOptimizationService() => _instance;\n  NetworkOptimizationService._internal();\n\n  final PerformanceService _performanceService = PerformanceService();\n  \n  // ìš”ì²­ ë°°ì¹˜ ì²˜ë¦¬\n  final Map<String, List<NetworkRequest>> _pendingRequests = {};\n  final Map<String, Timer> _batchTimers = {};\n  final Map<String, dynamic> _responseCache = {};\n  \n  // ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ê´€ë¦¬\n  NetworkConnectionType _connectionType = NetworkConnectionType.wifi;\n  bool _isOnline = true;\n  bool _isLowDataMode = false;\n  \n  // ìš”ì²­ í ë° ì¬ì‹œë„ ë¡œì§\n  final List<NetworkRequest> _retryQueue = [];\n  final Map<String, int> _retryCount = {};\n  Timer? _retryTimer;\n  \n  // ì„±ëŠ¥ ì„¤ì • (ì—°ê²° íƒ€ì…ë³„)\n  static const Map<NetworkConnectionType, NetworkConfig> _configs = {\n    NetworkConnectionType.wifi: NetworkConfig(\n      maxConcurrentRequests: 6,\n      timeoutDuration: Duration(seconds: 10),\n      retryAttempts: 3,\n      cacheDuration: Duration(minutes: 30),\n      batchDelay: Duration(milliseconds: 50),\n    ),\n    NetworkConnectionType.cellular: NetworkConfig(\n      maxConcurrentRequests: 3,\n      timeoutDuration: Duration(seconds: 15),\n      retryAttempts: 2,\n      cacheDuration: Duration(hours: 1),\n      batchDelay: Duration(milliseconds: 200),\n    ),\n    NetworkConnectionType.lowData: NetworkConfig(\n      maxConcurrentRequests: 1,\n      timeoutDuration: Duration(seconds: 20),\n      retryAttempts: 1,\n      cacheDuration: Duration(hours: 2),\n      batchDelay: Duration(milliseconds: 500),\n    ),\n  };\n  \n  NetworkConfig get currentConfig => _configs[_getCurrentConfigType()]!;\n  \n  NetworkConnectionType _getCurrentConfigType() {\n    if (_isLowDataMode) return NetworkConnectionType.lowData;\n    return _connectionType;\n  }\n  \n  // ì´ˆê¸°í™”\n  Future<void> initialize() async {\n    await _loadCachedData();\n    await _detectNetworkState();\n    _startRetryTimer();\n    \n    debugPrint('ğŸŒ NetworkOptimizationService initialized');\n  }\n  \n  Future<void> _detectNetworkState() async {\n    try {\n      // ì‹¤ì œ ì•±ì—ì„œëŠ” connectivity_plus íŒ¨í‚¤ì§€ ì‚¬ìš©\n      _connectionType = NetworkConnectionType.wifi;\n      _isOnline = true;\n      _isLowDataMode = false;\n      \n      debugPrint('ğŸ“¶ Network detected: $_connectionType, Online: $_isOnline');\n    } catch (e) {\n      debugPrint('Error detecting network state: $e');\n      _connectionType = NetworkConnectionType.cellular;\n      _isOnline = false;\n    }\n  }\n  \n  // ë°°ì¹˜ ìš”ì²­ ì²˜ë¦¬\n  Future<T> batchRequest<T>({\n    required String endpoint,\n    required String method,\n    Map<String, dynamic>? params,\n    Map<String, String>? headers,\n    required T Function(Map<String, dynamic>) parser,\n    bool priority = false,\n    Duration? customTimeout,\n  }) async {\n    final request = NetworkRequest<T>(\n      endpoint: endpoint,\n      method: method,\n      params: params,\n      headers: headers,\n      parser: parser,\n      priority: priority,\n      timeout: customTimeout ?? currentConfig.timeoutDuration,\n    );\n    \n    // ìºì‹œ í™•ì¸\n    final cacheKey = _generateCacheKey(endpoint, params);\n    if (_shouldUseCache(cacheKey)) {\n      final cached = _getCachedResponse<T>(cacheKey, parser);\n      if (cached != null) {\n        _performanceService.trackNetworkRequest(\n          endpoint,\n          Duration.zero,\n          200, // Cache hit\n        );\n        return cached;\n      }\n    }\n    \n    // ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì²˜ë¦¬\n    if (!_isOnline) {\n      final offlineData = await _getOfflineData<T>(cacheKey, parser);\n      if (offlineData != null) {\n        return offlineData;\n      }\n      throw NetworkException('ì˜¤í”„ë¼ì¸ ìƒíƒœì´ë©° ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤');\n    }\n    \n    // ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ìš”ì²­ì€ ì¦‰ì‹œ ì²˜ë¦¬\n    if (priority) {\n      return await _executeRequest(request);\n    }\n    \n    // ë°°ì¹˜ì— ì¶”ê°€\n    return await _addToBatch(request);\n  }\n  \n  Future<T> _addToBatch<T>(NetworkRequest<T> request) async {\n    final batchKey = _getBatchKey(request.endpoint, request.method);\n    \n    _pendingRequests.putIfAbsent(batchKey, () => []);\n    _pendingRequests[batchKey]!.add(request);\n    \n    // ë°°ì¹˜ íƒ€ì´ë¨¸ ì„¤ì •\n    _batchTimers[batchKey]?.cancel();\n    _batchTimers[batchKey] = Timer(currentConfig.batchDelay, () {\n      _processBatch(batchKey);\n    });\n    \n    return await request.completer.future;\n  }\n  \n  void _processBatch(String batchKey) async {\n    final requests = _pendingRequests.remove(batchKey) ?? [];\n    _batchTimers.remove(batchKey)?.cancel();\n    \n    if (requests.isEmpty) return;\n    \n    _performanceService.startOperation('batch_process_$batchKey');\n    \n    try {\n      // ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ\n      final chunks = _chunkRequests(requests, currentConfig.maxConcurrentRequests);\n      \n      for (final chunk in chunks) {\n        final futures = chunk.map((request) => _executeRequest(request));\n        await Future.wait(futures, eagerError: false);\n      }\n      \n      _performanceService.endOperation('batch_process_$batchKey', additionalData: {\n        'requests_count': requests.length,\n        'batch_key': batchKey,\n      });\n      \n    } catch (e) {\n      debugPrint('Batch processing error: $e');\n      _performanceService.endOperation('batch_process_$batchKey', additionalData: {\n        'error': e.toString(),\n      });\n    }\n  }\n  \n  List<List<NetworkRequest>> _chunkRequests(List<NetworkRequest> requests, int chunkSize) {\n    final chunks = <List<NetworkRequest>>[];\n    for (int i = 0; i < requests.length; i += chunkSize) {\n      chunks.add(requests.sublist(i, (i + chunkSize).clamp(0, requests.length)));\n    }\n    return chunks;\n  }\n  \n  Future<T> _executeRequest<T>(NetworkRequest<T> request) async {\n    final startTime = DateTime.now();\n    final requestId = '${request.endpoint}_${DateTime.now().millisecondsSinceEpoch}';\n    \n    try {\n      _performanceService.startOperation('network_request_$requestId');\n      \n      // ì‹¤ì œ HTTP ìš”ì²­ (ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜)\n      final response = await _simulateHttpRequest(request);\n      \n      final duration = DateTime.now().difference(startTime);\n      \n      // ì„±ê³µ ì‘ë‹µ ì²˜ë¦¬\n      final result = request.parser(response);\n      \n      // ìºì‹œ ì €ì¥\n      final cacheKey = _generateCacheKey(request.endpoint, request.params);\n      _cacheResponse(cacheKey, response);\n      \n      _performanceService.trackNetworkRequest(\n        request.endpoint,\n        duration,\n        200,\n      );\n      \n      _performanceService.endOperation('network_request_$requestId', additionalData: {\n        'endpoint': request.endpoint,\n        'duration_ms': duration.inMilliseconds,\n        'success': true,\n      });\n      \n      request.completer.complete(result);\n      return result;\n      \n    } catch (e) {\n      final duration = DateTime.now().difference(startTime);\n      \n      _performanceService.trackNetworkRequest(\n        request.endpoint,\n        duration,\n        -1, // Error code\n      );\n      \n      _performanceService.endOperation('network_request_$requestId', additionalData: {\n        'endpoint': request.endpoint,\n        'duration_ms': duration.inMilliseconds,\n        'success': false,\n        'error': e.toString(),\n      });\n      \n      // ì¬ì‹œë„ íì— ì¶”ê°€\n      _addToRetryQueue(request);\n      \n      request.completer.completeError(e);\n      rethrow;\n    }\n  }\n  \n  Future<Map<String, dynamic>> _simulateHttpRequest(NetworkRequest request) async {\n    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” http íŒ¨í‚¤ì§€ë‚˜ dio ì‚¬ìš©\n    await Future.delayed(Duration(\n      milliseconds: _connectionType == NetworkConnectionType.wifi ? 100 : 300,\n    ));\n    \n    // ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ\n    return {\n      'success': true,\n      'data': [],\n      'endpoint': request.endpoint,\n      'timestamp': DateTime.now().toIso8601String(),\n    };\n  }\n  \n  // ìºì‹œ ê´€ë¦¬\n  String _generateCacheKey(String endpoint, Map<String, dynamic>? params) {\n    final combined = '$endpoint${params != null ? jsonEncode(params) : ''}';\n    return combined.hashCode.toString();\n  }\n  \n  bool _shouldUseCache(String cacheKey) {\n    if (!_responseCache.containsKey(cacheKey)) return false;\n    \n    final cached = _responseCache[cacheKey];\n    final cacheTime = DateTime.parse(cached['timestamp']);\n    final now = DateTime.now();\n    \n    return now.difference(cacheTime) < currentConfig.cacheDuration;\n  }\n  \n  T? _getCachedResponse<T>(String cacheKey, T Function(Map<String, dynamic>) parser) {\n    try {\n      final cached = _responseCache[cacheKey];\n      if (cached != null) {\n        return parser(cached['data']);\n      }\n    } catch (e) {\n      debugPrint('Cache parsing error: $e');\n      _responseCache.remove(cacheKey);\n    }\n    return null;\n  }\n  \n  void _cacheResponse(String cacheKey, Map<String, dynamic> response) {\n    _responseCache[cacheKey] = {\n      'data': response,\n      'timestamp': DateTime.now().toIso8601String(),\n    };\n    \n    // ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ìµœì í™”)\n    if (_responseCache.length > 100) {\n      _cleanupCache();\n    }\n  }\n  \n  void _cleanupCache() {\n    final entries = _responseCache.entries.toList();\n    entries.sort((a, b) {\n      final timeA = DateTime.parse(a.value['timestamp']);\n      final timeB = DateTime.parse(b.value['timestamp']);\n      return timeA.compareTo(timeB);\n    });\n    \n    // ì˜¤ë˜ëœ ìºì‹œ 50% ì œê±°\n    final toRemove = entries.take(entries.length ~/ 2);\n    for (final entry in toRemove) {\n      _responseCache.remove(entry.key);\n    }\n    \n    debugPrint('ğŸ—‘ï¸ Cache cleanup: removed ${toRemove.length} entries');\n  }\n  \n  // ì¬ì‹œë„ ë¡œì§\n  void _addToRetryQueue(NetworkRequest request) {\n    final requestKey = '${request.endpoint}_${request.method}';\n    final currentRetries = _retryCount[requestKey] ?? 0;\n    \n    if (currentRetries < currentConfig.retryAttempts) {\n      _retryQueue.add(request);\n      _retryCount[requestKey] = currentRetries + 1;\n      \n      debugPrint('ğŸ“¤ Added to retry queue: ${request.endpoint} (attempt ${currentRetries + 1})');\n    } else {\n      debugPrint('âŒ Max retries exceeded for: ${request.endpoint}');\n      _retryCount.remove(requestKey);\n    }\n  }\n  \n  void _startRetryTimer() {\n    _retryTimer = Timer.periodic(const Duration(seconds: 5), (_) {\n      _processRetryQueue();\n    });\n  }\n  \n  void _processRetryQueue() async {\n    if (_retryQueue.isEmpty || !_isOnline) return;\n    \n    final request = _retryQueue.removeAt(0);\n    \n    try {\n      await _executeRequest(request);\n      final requestKey = '${request.endpoint}_${request.method}';\n      _retryCount.remove(requestKey);\n      \n      debugPrint('âœ… Retry successful: ${request.endpoint}');\n    } catch (e) {\n      debugPrint('ğŸ”„ Retry failed: ${request.endpoint}');\n    }\n  }\n  \n  // ì˜¤í”„ë¼ì¸ ì§€ì›\n  Future<T?> _getOfflineData<T>(String cacheKey, T Function(Map<String, dynamic>) parser) async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      final offlineData = prefs.getString('offline_$cacheKey');\n      \n      if (offlineData != null) {\n        final data = jsonDecode(offlineData);\n        return parser(data);\n      }\n    } catch (e) {\n      debugPrint('Offline data retrieval error: $e');\n    }\n    return null;\n  }\n  \n  Future<void> _saveOfflineData(String cacheKey, Map<String, dynamic> data) async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      await prefs.setString('offline_$cacheKey', jsonEncode(data));\n    } catch (e) {\n      debugPrint('Offline data save error: $e');\n    }\n  }\n  \n  Future<void> _loadCachedData() async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      final cacheData = prefs.getString('network_cache');\n      \n      if (cacheData != null) {\n        _responseCache.addAll(Map<String, dynamic>.from(jsonDecode(cacheData)));\n        debugPrint('ğŸ“¦ Loaded ${_responseCache.length} cached responses');\n      }\n    } catch (e) {\n      debugPrint('Cache loading error: $e');\n    }\n  }\n  \n  Future<void> saveCacheData() async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      await prefs.setString('network_cache', jsonEncode(_responseCache));\n    } catch (e) {\n      debugPrint('Cache saving error: $e');\n    }\n  }\n  \n  // ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ì—…ë°ì´íŠ¸\n  void updateNetworkState({\n    required NetworkConnectionType connectionType,\n    required bool isOnline,\n    bool isLowDataMode = false,\n  }) {\n    _connectionType = connectionType;\n    _isOnline = isOnline;\n    _isLowDataMode = isLowDataMode;\n    \n    debugPrint('ğŸŒ Network state updated: $connectionType, online: $isOnline, lowData: $isLowDataMode');\n  }\n  \n  // ë°°ì¹˜ í‚¤ ìƒì„±\n  String _getBatchKey(String endpoint, String method) {\n    // ê°™ì€ ì—”ë“œí¬ì¸íŠ¸ì™€ ë©”ì†Œë“œë¥¼ ê°€ì§„ ìš”ì²­ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬\n    return '${endpoint}_$method';\n  }\n  \n  // ì •ë¦¬\n  void dispose() {\n    _batchTimers.values.forEach((timer) => timer.cancel());\n    _retryTimer?.cancel();\n    saveCacheData();\n    \n    debugPrint('ğŸŒ NetworkOptimizationService disposed');\n  }\n  \n  // í†µê³„ ì •ë³´\n  NetworkStats getStats() {\n    return NetworkStats(\n      cacheHitCount: _responseCache.length,\n      pendingRequestsCount: _pendingRequests.values.fold(0, (sum, list) => sum + list.length),\n      retryQueueCount: _retryQueue.length,\n      connectionType: _connectionType,\n      isOnline: _isOnline,\n    );\n  }\n}\n\n// ë°ì´í„° í´ë˜ìŠ¤ë“¤\nclass NetworkRequest<T> {\n  final String endpoint;\n  final String method;\n  final Map<String, dynamic>? params;\n  final Map<String, String>? headers;\n  final T Function(Map<String, dynamic>) parser;\n  final bool priority;\n  final Duration timeout;\n  final Completer<T> completer = Completer<T>();\n  \n  NetworkRequest({\n    required this.endpoint,\n    required this.method,\n    this.params,\n    this.headers,\n    required this.parser,\n    this.priority = false,\n    required this.timeout,\n  });\n}\n\nclass NetworkConfig {\n  final int maxConcurrentRequests;\n  final Duration timeoutDuration;\n  final int retryAttempts;\n  final Duration cacheDuration;\n  final Duration batchDelay;\n  \n  const NetworkConfig({\n    required this.maxConcurrentRequests,\n    required this.timeoutDuration,\n    required this.retryAttempts,\n    required this.cacheDuration,\n    required this.batchDelay,\n  });\n}\n\nenum NetworkConnectionType {\n  wifi,\n  cellular,\n  lowData,\n}\n\nclass NetworkStats {\n  final int cacheHitCount;\n  final int pendingRequestsCount;\n  final int retryQueueCount;\n  final NetworkConnectionType connectionType;\n  final bool isOnline;\n  \n  const NetworkStats({\n    required this.cacheHitCount,\n    required this.pendingRequestsCount,\n    required this.retryQueueCount,\n    required this.connectionType,\n    required this.isOnline,\n  });\n  \n  @override\n  String toString() {\n    return '''\nNetwork Stats:\n  Cache Hits: $cacheHitCount\n  Pending Requests: $pendingRequestsCount\n  Retry Queue: $retryQueueCount\n  Connection: $connectionType\n  Online: $isOnline\n''';\n  }\n}\n\nclass NetworkException implements Exception {\n  final String message;\n  NetworkException(this.message);\n  \n  @override\n  String toString() => 'NetworkException: $message';\n}\n\n// í•œêµ­ ëª¨ë°”ì¼ í™˜ê²½ ìµœì í™” ìœ í‹¸ë¦¬í‹°\nclass KoreanNetworkOptimizations {\n  // ë‹¹ê·¼ë§ˆì¼“ ìŠ¤íƒ€ì¼ ë¹ ë¥¸ ì‘ë‹µ\n  static Future<T> fastRequest<T>({\n    required String endpoint,\n    required T Function(Map<String, dynamic>) parser,\n    Map<String, dynamic>? params,\n  }) {\n    return NetworkOptimizationService().batchRequest(\n      endpoint: endpoint,\n      method: 'GET',\n      params: params,\n      parser: parser,\n      priority: true, // ìš°ì„ ìˆœìœ„ ë†’ìŒ\n    );\n  }\n  \n  // ì¿ íŒ¡ ìŠ¤íƒ€ì¼ ë°°ì¹˜ ë¡œë”©\n  static Future<T> batchLoad<T>({\n    required String endpoint,\n    required T Function(Map<String, dynamic>) parser,\n    Map<String, dynamic>? params,\n  }) {\n    return NetworkOptimizationService().batchRequest(\n      endpoint: endpoint,\n      method: 'GET',\n      params: params,\n      parser: parser,\n      priority: false, // ë°°ì¹˜ ì²˜ë¦¬\n    );\n  }\n  \n  // ë„¤ì´ë²„ ìŠ¤íƒ€ì¼ ìºì‹œ ìš°ì„ \n  static Future<T> cachedRequest<T>({\n    required String endpoint,\n    required T Function(Map<String, dynamic>) parser,\n    Map<String, dynamic>? params,\n  }) {\n    return NetworkOptimizationService().batchRequest(\n      endpoint: endpoint,\n      method: 'GET',\n      params: params,\n      parser: parser,\n      customTimeout: const Duration(minutes: 1), // ê¸´ ìºì‹œ ì‹œê°„\n    );\n  }\n}