import 'dart:async';\nimport 'dart:convert';\nimport 'dart:io';\nimport 'package:flutter/foundation.dart';\nimport 'package:flutter/services.dart';\nimport 'package:shared_preferences/shared_preferences.dart';\nimport 'performance_service.dart';\n\n// 네트워크 최적화 서비스 - 한국 모바일 환경 특화\nclass NetworkOptimizationService {\n  static final NetworkOptimizationService _instance = NetworkOptimizationService._internal();\n  factory NetworkOptimizationService() => _instance;\n  NetworkOptimizationService._internal();\n\n  final PerformanceService _performanceService = PerformanceService();\n  \n  // 요청 배치 처리\n  final Map<String, List<NetworkRequest>> _pendingRequests = {};\n  final Map<String, Timer> _batchTimers = {};\n  final Map<String, dynamic> _responseCache = {};\n  \n  // 네트워크 상태 관리\n  NetworkConnectionType _connectionType = NetworkConnectionType.wifi;\n  bool _isOnline = true;\n  bool _isLowDataMode = false;\n  \n  // 요청 큐 및 재시도 로직\n  final List<NetworkRequest> _retryQueue = [];\n  final Map<String, int> _retryCount = {};\n  Timer? _retryTimer;\n  \n  // 성능 설정 (연결 타입별)\n  static const Map<NetworkConnectionType, NetworkConfig> _configs = {\n    NetworkConnectionType.wifi: NetworkConfig(\n      maxConcurrentRequests: 6,\n      timeoutDuration: Duration(seconds: 10),\n      retryAttempts: 3,\n      cacheDuration: Duration(minutes: 30),\n      batchDelay: Duration(milliseconds: 50),\n    ),\n    NetworkConnectionType.cellular: NetworkConfig(\n      maxConcurrentRequests: 3,\n      timeoutDuration: Duration(seconds: 15),\n      retryAttempts: 2,\n      cacheDuration: Duration(hours: 1),\n      batchDelay: Duration(milliseconds: 200),\n    ),\n    NetworkConnectionType.lowData: NetworkConfig(\n      maxConcurrentRequests: 1,\n      timeoutDuration: Duration(seconds: 20),\n      retryAttempts: 1,\n      cacheDuration: Duration(hours: 2),\n      batchDelay: Duration(milliseconds: 500),\n    ),\n  };\n  \n  NetworkConfig get currentConfig => _configs[_getCurrentConfigType()]!;\n  \n  NetworkConnectionType _getCurrentConfigType() {\n    if (_isLowDataMode) return NetworkConnectionType.lowData;\n    return _connectionType;\n  }\n  \n  // 초기화\n  Future<void> initialize() async {\n    await _loadCachedData();\n    await _detectNetworkState();\n    _startRetryTimer();\n    \n    debugPrint('🌐 NetworkOptimizationService initialized');\n  }\n  \n  Future<void> _detectNetworkState() async {\n    try {\n      // 실제 앱에서는 connectivity_plus 패키지 사용\n      _connectionType = NetworkConnectionType.wifi;\n      _isOnline = true;\n      _isLowDataMode = false;\n      \n      debugPrint('📶 Network detected: $_connectionType, Online: $_isOnline');\n    } catch (e) {\n      debugPrint('Error detecting network state: $e');\n      _connectionType = NetworkConnectionType.cellular;\n      _isOnline = false;\n    }\n  }\n  \n  // 배치 요청 처리\n  Future<T> batchRequest<T>({\n    required String endpoint,\n    required String method,\n    Map<String, dynamic>? params,\n    Map<String, String>? headers,\n    required T Function(Map<String, dynamic>) parser,\n    bool priority = false,\n    Duration? customTimeout,\n  }) async {\n    final request = NetworkRequest<T>(\n      endpoint: endpoint,\n      method: method,\n      params: params,\n      headers: headers,\n      parser: parser,\n      priority: priority,\n      timeout: customTimeout ?? currentConfig.timeoutDuration,\n    );\n    \n    // 캐시 확인\n    final cacheKey = _generateCacheKey(endpoint, params);\n    if (_shouldUseCache(cacheKey)) {\n      final cached = _getCachedResponse<T>(cacheKey, parser);\n      if (cached != null) {\n        _performanceService.trackNetworkRequest(\n          endpoint,\n          Duration.zero,\n          200, // Cache hit\n        );\n        return cached;\n      }\n    }\n    \n    // 오프라인 모드 처리\n    if (!_isOnline) {\n      final offlineData = await _getOfflineData<T>(cacheKey, parser);\n      if (offlineData != null) {\n        return offlineData;\n      }\n      throw NetworkException('오프라인 상태이며 캐시된 데이터가 없습니다');\n    }\n    \n    // 우선순위가 높은 요청은 즉시 처리\n    if (priority) {\n      return await _executeRequest(request);\n    }\n    \n    // 배치에 추가\n    return await _addToBatch(request);\n  }\n  \n  Future<T> _addToBatch<T>(NetworkRequest<T> request) async {\n    final batchKey = _getBatchKey(request.endpoint, request.method);\n    \n    _pendingRequests.putIfAbsent(batchKey, () => []);\n    _pendingRequests[batchKey]!.add(request);\n    \n    // 배치 타이머 설정\n    _batchTimers[batchKey]?.cancel();\n    _batchTimers[batchKey] = Timer(currentConfig.batchDelay, () {\n      _processBatch(batchKey);\n    });\n    \n    return await request.completer.future;\n  }\n  \n  void _processBatch(String batchKey) async {\n    final requests = _pendingRequests.remove(batchKey) ?? [];\n    _batchTimers.remove(batchKey)?.cancel();\n    \n    if (requests.isEmpty) return;\n    \n    _performanceService.startOperation('batch_process_$batchKey');\n    \n    try {\n      // 동시 실행 수 제한\n      final chunks = _chunkRequests(requests, currentConfig.maxConcurrentRequests);\n      \n      for (final chunk in chunks) {\n        final futures = chunk.map((request) => _executeRequest(request));\n        await Future.wait(futures, eagerError: false);\n      }\n      \n      _performanceService.endOperation('batch_process_$batchKey', additionalData: {\n        'requests_count': requests.length,\n        'batch_key': batchKey,\n      });\n      \n    } catch (e) {\n      debugPrint('Batch processing error: $e');\n      _performanceService.endOperation('batch_process_$batchKey', additionalData: {\n        'error': e.toString(),\n      });\n    }\n  }\n  \n  List<List<NetworkRequest>> _chunkRequests(List<NetworkRequest> requests, int chunkSize) {\n    final chunks = <List<NetworkRequest>>[];\n    for (int i = 0; i < requests.length; i += chunkSize) {\n      chunks.add(requests.sublist(i, (i + chunkSize).clamp(0, requests.length)));\n    }\n    return chunks;\n  }\n  \n  Future<T> _executeRequest<T>(NetworkRequest<T> request) async {\n    final startTime = DateTime.now();\n    final requestId = '${request.endpoint}_${DateTime.now().millisecondsSinceEpoch}';\n    \n    try {\n      _performanceService.startOperation('network_request_$requestId');\n      \n      // 실제 HTTP 요청 (여기서는 시뮬레이션)\n      final response = await _simulateHttpRequest(request);\n      \n      final duration = DateTime.now().difference(startTime);\n      \n      // 성공 응답 처리\n      final result = request.parser(response);\n      \n      // 캐시 저장\n      final cacheKey = _generateCacheKey(request.endpoint, request.params);\n      _cacheResponse(cacheKey, response);\n      \n      _performanceService.trackNetworkRequest(\n        request.endpoint,\n        duration,\n        200,\n      );\n      \n      _performanceService.endOperation('network_request_$requestId', additionalData: {\n        'endpoint': request.endpoint,\n        'duration_ms': duration.inMilliseconds,\n        'success': true,\n      });\n      \n      request.completer.complete(result);\n      return result;\n      \n    } catch (e) {\n      final duration = DateTime.now().difference(startTime);\n      \n      _performanceService.trackNetworkRequest(\n        request.endpoint,\n        duration,\n        -1, // Error code\n      );\n      \n      _performanceService.endOperation('network_request_$requestId', additionalData: {\n        'endpoint': request.endpoint,\n        'duration_ms': duration.inMilliseconds,\n        'success': false,\n        'error': e.toString(),\n      });\n      \n      // 재시도 큐에 추가\n      _addToRetryQueue(request);\n      \n      request.completer.completeError(e);\n      rethrow;\n    }\n  }\n  \n  Future<Map<String, dynamic>> _simulateHttpRequest(NetworkRequest request) async {\n    // 실제 구현에서는 http 패키지나 dio 사용\n    await Future.delayed(Duration(\n      milliseconds: _connectionType == NetworkConnectionType.wifi ? 100 : 300,\n    ));\n    \n    // 시뮬레이션된 응답\n    return {\n      'success': true,\n      'data': [],\n      'endpoint': request.endpoint,\n      'timestamp': DateTime.now().toIso8601String(),\n    };\n  }\n  \n  // 캐시 관리\n  String _generateCacheKey(String endpoint, Map<String, dynamic>? params) {\n    final combined = '$endpoint${params != null ? jsonEncode(params) : ''}';\n    return combined.hashCode.toString();\n  }\n  \n  bool _shouldUseCache(String cacheKey) {\n    if (!_responseCache.containsKey(cacheKey)) return false;\n    \n    final cached = _responseCache[cacheKey];\n    final cacheTime = DateTime.parse(cached['timestamp']);\n    final now = DateTime.now();\n    \n    return now.difference(cacheTime) < currentConfig.cacheDuration;\n  }\n  \n  T? _getCachedResponse<T>(String cacheKey, T Function(Map<String, dynamic>) parser) {\n    try {\n      final cached = _responseCache[cacheKey];\n      if (cached != null) {\n        return parser(cached['data']);\n      }\n    } catch (e) {\n      debugPrint('Cache parsing error: $e');\n      _responseCache.remove(cacheKey);\n    }\n    return null;\n  }\n  \n  void _cacheResponse(String cacheKey, Map<String, dynamic> response) {\n    _responseCache[cacheKey] = {\n      'data': response,\n      'timestamp': DateTime.now().toIso8601String(),\n    };\n    \n    // 캐시 크기 제한 (메모리 최적화)\n    if (_responseCache.length > 100) {\n      _cleanupCache();\n    }\n  }\n  \n  void _cleanupCache() {\n    final entries = _responseCache.entries.toList();\n    entries.sort((a, b) {\n      final timeA = DateTime.parse(a.value['timestamp']);\n      final timeB = DateTime.parse(b.value['timestamp']);\n      return timeA.compareTo(timeB);\n    });\n    \n    // 오래된 캐시 50% 제거\n    final toRemove = entries.take(entries.length ~/ 2);\n    for (final entry in toRemove) {\n      _responseCache.remove(entry.key);\n    }\n    \n    debugPrint('🗑️ Cache cleanup: removed ${toRemove.length} entries');\n  }\n  \n  // 재시도 로직\n  void _addToRetryQueue(NetworkRequest request) {\n    final requestKey = '${request.endpoint}_${request.method}';\n    final currentRetries = _retryCount[requestKey] ?? 0;\n    \n    if (currentRetries < currentConfig.retryAttempts) {\n      _retryQueue.add(request);\n      _retryCount[requestKey] = currentRetries + 1;\n      \n      debugPrint('📤 Added to retry queue: ${request.endpoint} (attempt ${currentRetries + 1})');\n    } else {\n      debugPrint('❌ Max retries exceeded for: ${request.endpoint}');\n      _retryCount.remove(requestKey);\n    }\n  }\n  \n  void _startRetryTimer() {\n    _retryTimer = Timer.periodic(const Duration(seconds: 5), (_) {\n      _processRetryQueue();\n    });\n  }\n  \n  void _processRetryQueue() async {\n    if (_retryQueue.isEmpty || !_isOnline) return;\n    \n    final request = _retryQueue.removeAt(0);\n    \n    try {\n      await _executeRequest(request);\n      final requestKey = '${request.endpoint}_${request.method}';\n      _retryCount.remove(requestKey);\n      \n      debugPrint('✅ Retry successful: ${request.endpoint}');\n    } catch (e) {\n      debugPrint('🔄 Retry failed: ${request.endpoint}');\n    }\n  }\n  \n  // 오프라인 지원\n  Future<T?> _getOfflineData<T>(String cacheKey, T Function(Map<String, dynamic>) parser) async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      final offlineData = prefs.getString('offline_$cacheKey');\n      \n      if (offlineData != null) {\n        final data = jsonDecode(offlineData);\n        return parser(data);\n      }\n    } catch (e) {\n      debugPrint('Offline data retrieval error: $e');\n    }\n    return null;\n  }\n  \n  Future<void> _saveOfflineData(String cacheKey, Map<String, dynamic> data) async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      await prefs.setString('offline_$cacheKey', jsonEncode(data));\n    } catch (e) {\n      debugPrint('Offline data save error: $e');\n    }\n  }\n  \n  Future<void> _loadCachedData() async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      final cacheData = prefs.getString('network_cache');\n      \n      if (cacheData != null) {\n        _responseCache.addAll(Map<String, dynamic>.from(jsonDecode(cacheData)));\n        debugPrint('📦 Loaded ${_responseCache.length} cached responses');\n      }\n    } catch (e) {\n      debugPrint('Cache loading error: $e');\n    }\n  }\n  \n  Future<void> saveCacheData() async {\n    try {\n      final prefs = await SharedPreferences.getInstance();\n      await prefs.setString('network_cache', jsonEncode(_responseCache));\n    } catch (e) {\n      debugPrint('Cache saving error: $e');\n    }\n  }\n  \n  // 네트워크 상태 업데이트\n  void updateNetworkState({\n    required NetworkConnectionType connectionType,\n    required bool isOnline,\n    bool isLowDataMode = false,\n  }) {\n    _connectionType = connectionType;\n    _isOnline = isOnline;\n    _isLowDataMode = isLowDataMode;\n    \n    debugPrint('🌐 Network state updated: $connectionType, online: $isOnline, lowData: $isLowDataMode');\n  }\n  \n  // 배치 키 생성\n  String _getBatchKey(String endpoint, String method) {\n    // 같은 엔드포인트와 메소드를 가진 요청들을 배치로 처리\n    return '${endpoint}_$method';\n  }\n  \n  // 정리\n  void dispose() {\n    _batchTimers.values.forEach((timer) => timer.cancel());\n    _retryTimer?.cancel();\n    saveCacheData();\n    \n    debugPrint('🌐 NetworkOptimizationService disposed');\n  }\n  \n  // 통계 정보\n  NetworkStats getStats() {\n    return NetworkStats(\n      cacheHitCount: _responseCache.length,\n      pendingRequestsCount: _pendingRequests.values.fold(0, (sum, list) => sum + list.length),\n      retryQueueCount: _retryQueue.length,\n      connectionType: _connectionType,\n      isOnline: _isOnline,\n    );\n  }\n}\n\n// 데이터 클래스들\nclass NetworkRequest<T> {\n  final String endpoint;\n  final String method;\n  final Map<String, dynamic>? params;\n  final Map<String, String>? headers;\n  final T Function(Map<String, dynamic>) parser;\n  final bool priority;\n  final Duration timeout;\n  final Completer<T> completer = Completer<T>();\n  \n  NetworkRequest({\n    required this.endpoint,\n    required this.method,\n    this.params,\n    this.headers,\n    required this.parser,\n    this.priority = false,\n    required this.timeout,\n  });\n}\n\nclass NetworkConfig {\n  final int maxConcurrentRequests;\n  final Duration timeoutDuration;\n  final int retryAttempts;\n  final Duration cacheDuration;\n  final Duration batchDelay;\n  \n  const NetworkConfig({\n    required this.maxConcurrentRequests,\n    required this.timeoutDuration,\n    required this.retryAttempts,\n    required this.cacheDuration,\n    required this.batchDelay,\n  });\n}\n\nenum NetworkConnectionType {\n  wifi,\n  cellular,\n  lowData,\n}\n\nclass NetworkStats {\n  final int cacheHitCount;\n  final int pendingRequestsCount;\n  final int retryQueueCount;\n  final NetworkConnectionType connectionType;\n  final bool isOnline;\n  \n  const NetworkStats({\n    required this.cacheHitCount,\n    required this.pendingRequestsCount,\n    required this.retryQueueCount,\n    required this.connectionType,\n    required this.isOnline,\n  });\n  \n  @override\n  String toString() {\n    return '''\nNetwork Stats:\n  Cache Hits: $cacheHitCount\n  Pending Requests: $pendingRequestsCount\n  Retry Queue: $retryQueueCount\n  Connection: $connectionType\n  Online: $isOnline\n''';\n  }\n}\n\nclass NetworkException implements Exception {\n  final String message;\n  NetworkException(this.message);\n  \n  @override\n  String toString() => 'NetworkException: $message';\n}\n\n// 한국 모바일 환경 최적화 유틸리티\nclass KoreanNetworkOptimizations {\n  // 당근마켓 스타일 빠른 응답\n  static Future<T> fastRequest<T>({\n    required String endpoint,\n    required T Function(Map<String, dynamic>) parser,\n    Map<String, dynamic>? params,\n  }) {\n    return NetworkOptimizationService().batchRequest(\n      endpoint: endpoint,\n      method: 'GET',\n      params: params,\n      parser: parser,\n      priority: true, // 우선순위 높음\n    );\n  }\n  \n  // 쿠팡 스타일 배치 로딩\n  static Future<T> batchLoad<T>({\n    required String endpoint,\n    required T Function(Map<String, dynamic>) parser,\n    Map<String, dynamic>? params,\n  }) {\n    return NetworkOptimizationService().batchRequest(\n      endpoint: endpoint,\n      method: 'GET',\n      params: params,\n      parser: parser,\n      priority: false, // 배치 처리\n    );\n  }\n  \n  // 네이버 스타일 캐시 우선\n  static Future<T> cachedRequest<T>({\n    required String endpoint,\n    required T Function(Map<String, dynamic>) parser,\n    Map<String, dynamic>? params,\n  }) {\n    return NetworkOptimizationService().batchRequest(\n      endpoint: endpoint,\n      method: 'GET',\n      params: params,\n      parser: parser,\n      customTimeout: const Duration(minutes: 1), // 긴 캐시 시간\n    );\n  }\n}